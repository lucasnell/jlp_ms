---
title: "jackalope: a swift, light-weight phylogenomic and high-throughput sequencing simulator"
bibliography: "references.bib"
csl: "apa.csl"
fontsize: 12pt
geometry: margin=1in,letterpaper
documentclass: article
tables: true
graphics: true
colorlinks: true
mathspec: true
linestretch: 1.5
sectionbreaks: true
sectionnumbering: true
raggedtoc: true
output: 
    bookdown::pdf_document2:
        fig_caption: yes
        keep_tex: yes
        number_sections: no
        toc: no
        highlight: haddock
editor_options:
    chunk_output_type: console
---


```{r setup, include=FALSE, cache = FALSE}
suppressPackageStartupMessages({
    library(knitr)
    library(knitcitations)
    library(tidyverse)
    library(jackalope)
    library(scrm)
    library(ape)
})
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, eval = FALSE, dev = 'quartz_pdf')

theme_set(theme_classic() + 
              theme(legend.background = element_blank(),
                    strip.background = element_blank(),
                    plot.margin = margin(0.5, 0.5, 0.5, 2)))
if (!isTRUE(getOption('knitr.in.progress'))) {
    options("device" = "quartz")
    grDevices::graphics.off()
}

cleanbib()
options("citation_format" = "pandoc", knitr.graphics.auto_pdf = TRUE)

old_ref <- function(key, parenth = TRUE) {
    if (parenth) {
        citep(bibtex::read.bib(file = 'old_refs.bib')[key])
    } else {
        citet(bibtex::read.bib(file = 'old_refs.bib')[key])
    }
}
no_auth <- function(key) gsub("@", "-@", key)
old_new <- function(old, new) {
    old_ <- old_ref(old)
    new_ <- citep(new)
    paste(gsub("\\]", "", old_), gsub("\\[", "", new_), sep = "; ")
}
# Sort citations as they'll appear in the in-text citation: by year, then name
sort_cit <- function(citation) {
    split_cit <- {str_split(citation, "; ")[[1]]} %>%
        str_replace_all("\\[|\\]", "")
    years <- split_cit %>%
        str_split("_") %>% 
        map_chr(~ tail(.x, 1))
    names <- split_cit %>% 
        str_split("_") %>% 
        map_chr(~ head(.x, -1) %>% str_c(collapse = "_"))
    output <- split_cit[order(years, names)] %>% 
        str_c(collapse = "; ")
    return(output)
}
prefix <- function(pre, citation) {
    sorted_cit <- sort_cit(citation)
    output <- sprintf(fmt = "[%s %s]", pre, sorted_cit)
    return(output)
}
suffix <- function(citation, suf) {
    sorted_cit <- sort_cit(citation)
    output <- sprintf(fmt = "[%s %s]", sorted_cit, suf)
    return(output)
}
prefix_suffix <- function(pre, citation, suf) {
    sorted_cit <- sort_cit(citation)
    output <- sprintf(fmt = "[%s %s %s]", pre, sorted_cit, suf)
    return(output)
}

# Allows you to specify the title yourself for calls to `citation` inside `citep`
keep_title <- function(pkg_name, set_title = NULL, index = NULL) {
    z <- citation(pkg_name)
    if (!is.null(index)) z <- z[index]
    if (is.null(set_title)) {
        z$title <- sprintf("{%s}", z$title)
    } else {
        z$title <- set_title
    }
    return(citep(z))
}

# Function to print data frames for LaTeX output using booktabs package
pretty_df <- function(df_, caption = NULL, edit_nums = FALSE) {
    edit_nums_fxn <- function(.df){
        .df %>%
            mutate_if(is.numeric,
                      function(x) {
                          x %>% sprintf(fmt = '%.4g') %>%
                              sapply(., parse_scinot)
                      })
    }
    if (edit_nums) {
        if (is(df_, 'list')) {
            df_ <- lapply(df_, edit_nums_fxn)
        } else {
            df_ <- edit_nums_fxn(df_)
        }
    }
    kable_obj <- knitr::kable(df_, format = 'latex', booktabs = TRUE,
                              caption = caption, escape = FALSE)
    kable_str <- unlist(str_split(kable_obj, '\n'))
    kable_str <- kable_str[kable_str != "\\addlinespace"]
    for (i in 1:(length(kable_str)-1)) {
        if (grepl('^ &', kable_str[i]) & !grepl('^ &', kable_str[(i+1)]) &
            !grepl('^\\bottomrule', kable_str[(i+1)])) {
            kable_str[i] <- str_c(kable_str[i], "\n", "\\addlinespace")
        }
    }
    new_kable_str <- str_c(kable_str, collapse = '\n')
    kable_obj[1] <- new_kable_str
    return(kable_obj)
}

# Removes "e+X" or "e-X" (X is a 2-character number like "04" or "22"), converts to
# "2 \times 10^Z" for LaTeX (Z is a normal number like "4" or "-22")
pretty_num <- function(num, sigfigs = 2) {
    
    nstr <- sprintf(fmt = paste0("%.",sigfigs,"g"), num)
    
    if (str_detect(nstr, 'e-0')) {
        nstr <- str_replace(nstr, "e-0", " \\\\times 10^\\{-") %>% str_c("}")
    } else if (str_detect(nstr, 'e-')) {
        nstr <- str_replace(nstr, "e-", " \\\\times 10^\\{-") %>% str_c("}")
    } else if (str_detect(nstr, 'e\\+0')) {
        nstr <- str_replace(nstr, "e\\+0", " \\\\times 10^")
    } else if (str_detect(nstr, 'e\\+')) {
        nstr <- str_replace(nstr, "e\\+", " \\\\times 10^")
    }
    return(nstr)
}
```


## Abstract

High-throughput sequencing (HTS) is central to the study of population genomics.
Choices in sampling design for sequencing projects can include 
sequencing platform, depth of coverage, and number of individuals to sample.
These choices are most often informed by previous work on highly diverged species, 
which ignores species- and population-specific genomic characteristics, demographies, 
and evolutionary histories.
Simulating sequencing based on available genomic data better informs sampling
strategies.

However, current methods provide only rudimentary ways to simulate population
histories.
More recent pipelines have been developed that can simulate complex evolutionary 


Here I present the R package `jackalope` that efficiently 
(i) reads and simulates reference genomes;
(ii) generates variants using summary statistics, phylogenies, 
Variant Call Format (VCF) files, and coalescent simulations---the latter of which can
include selection, recombination, and demographic fluctuations;
(iii) simulates sequencing error, mapping qualities, multiplexing, and
optical/PCR duplicates;
and
(iv) writes outputs to standard file formats.
`jackalope` can simulate single, paired-end, or mate-pair Illumina reads,
as well as reads from Pacific BioSciences.


Most functions are written in C++ to improve performance, and I employed OpenMP to 
allow for parallel processing.
`jackalope` is available on GitHub
(https://github.com/lucasnell/jackalope).


<!-- The stable version of `jackalope` is available on CRAN -->
<!-- (https://CRAN.R-project.org/package=jackalope), -->
<!-- and the development version is on GitHub -->
<!-- (https://github.com/lucasnell/jackalope). -->


<!-- ### Assembling a genome -->
<!-- ### Estimating divergence between populations -->
<!-- ### Constructing a phylogeny -->


<!-- 4-6 keywords -->

__Keywords\:__ sequencing simulator, population genomics, phylogenomics,
Illumina, Pacific Biosciences, Pool-seq



## Introduction



High-throughput sequencing (HTS) is a cost-effective approach to generate vast amounts
of genomic data and has revolutionized the study of genomes
`r citep("10.1038/nrg2626")`.
The combination of massive datasets, sequencing errors, and potentially complex
evolutionary histories make bioinformatic pipelines an important aspect of
research using HTS.
Many bioinformatic tools exist, and new programs that are more accurate and
computationally efficient are constantly being developed.
To test these tools against known parameter values, simulation of HTS data is needed.
Although there are many sequence simulators currently available
`r prefix("reviewed in", citep("10.1038/nrg.2016.57"))`,
most have only rudimentary ways to generate variants from a reference genome.


Recently, pipelines have been developed that use multiple programs
to simulate complex evolutionary histories and HTS on the resulting populations
or species.
`TreeToReads` can simulate sequences along a single phylogenetic tree 
`r citep("10.1186/s12859-017-1592-1")`, and
`NGSphy` can generate sequences from multiple gene trees
`r citep("10.1093/bioinformatics/bty146")`;
both then generate Illumina reads.
These pipelines are quite powerful and useful to those seeking to simulate
HTS data under realistic evolutionary scenarios.
However, both pipelines require the installation of multiple programs to use them,
and the vast array of features creates a steep learning curve when getting started.
Additionally, the lack of integration between inner programs means that the
entire process is not as computationally efficient as a single standalone program.


In the present paper I introduce `jackalope`, the first available high-throughput
DNA-sequencing simulator for R
`r keep_title("base", "{R:} A Language and Environment for Statistical Computing")`.
Designed for efficient memory use, flexibility, and speed,
`jackalope` combines the functionality of an HTS simulator with that of a
phylogenomics simulator.
Genomes can be derived from FASTA files or simulated in silico.
`jackalope` can create variants from the reference genome based on basic 
population-genomic summary statistics, phylogenies, gene trees, 
Variant Call Format (VCF) files, or matrices of segregating sites.
These variants can be simulated based on any of several popular
molecular-evolution models.
`jackalope` simulates single, paired-ended, or mate-pair reads on the Illumina platform,
as well as Pacific Biosciences (PacBio) reads.
All information generated by `jackalope` can be output to standard file formats.


After outlining the methods, I compare the performance of `jackalope` to that of 
other popular programs.
Lastly, I demonstrate the usefulness of `jackalope` through three usage examples.







## Features and methods

Most code is written in C++ and interfaces with R using the `Rcpp` package
`r citep(citation("Rcpp")[1])`.
I used OpenMP to allow for parallel processing and
the `PCG` family of thread-safe, pseudo-random number generators
`r old_ref("Oneill_2014pcg")`.
Package `RcppProgress` provides the thread-safe progress bar
`r citep(citation("RcppProgress"))`.
All input and output files can have `gzip` or `bgzip` compression, using the
`zlib` and
`htslib` `r citep(":10.1093/bioinformatics/btp352")` libraries.
Access to these libraries uses the R packages
`zlibbioc` `r citep(citation("zlibbioc"))` and
`Rhtslib` `r citep(citation("Rhtslib"))`
to improve portability.
An overview of the methods are show in Figure \@ref(fig:jackalope-overview-figure).

```{r jackalope-overview-cap, include=FALSE, eval = TRUE}
go_cap <- paste("Overview of primary \\texttt{jackalope} functions, classes,",
                "inputs, and outputs.",
                "Circles \\texttt{sub_models} and \\texttt{vars_functions}",
                "refer to multiple functions; see text for details.",
                "$\\theta$ indicates the population-scaled mutation rate.")
```
```{r jackalope-overview-figure, out.width="100%", out.height="100%", fig.cap=go_cap, echo = FALSE, eval = TRUE}
knitr::include_graphics("figs/jackalope.pdf", dpi = NA)
```





### The `ref_genome` class

Haploid reference genomes are represented by the class `ref_genome`, an
R6 `r citep(citation("R6"))` class that acts as a wrapper around a pointer to 
an underlying C++ object that stores all the sequence information.
They can be generated from FASTA files using the function `read_fasta`.
This function also accepts FASTA index files---created using 
`samtools faidx`---for faster processing.
If a reference genome is not available, the `create_genome` function creates 
a reference genome of given equilibrium nucleotide distributions.
Sequence lengths are drawn from a gamma distribution `r citep("10.1093/molbev/msr011")`
with a mean and standard deviation provided by the user.


The access provided by the R class `ref_genome` is designed to both 
maximize flexibility and minimize copying and the chances of
printing extremely large strings to the console.
Methods in `ref_genome` allow the user to view the
number of sequences, sequence sizes, sequence names, individual sequence strings,
and nucleotide proportions (GC or otherwise).
Users can also edit sequence names, remove one or more sequences by name,
and add sequences manually.
Method `filter_sequences` filters genomes by the minimum sequence size or
by the smallest sequence that retains a given proportion of total reference
sequence if sequences are sorted by descending size.
Using method `merge_sequences`, users can shuffle reference sequences and
merge them into one.
Method `replace_Ns` replaces any `N`s in the reference sequence with nucleotides
that are sampled with weights proportional to their equilibrium distributions 
(provided by the user).
Reference genomes can be written to FASTA files using the `write_fasta` function.




### Creating variants


Haploid variants from the reference genome are generated using the
`create_variants` function.
To organize a potentially large amount of information that can be input to this function,
I added helper functions that handle parts of the input.
There are helper functions for the higher-level method information
(information from phylogenies, coalescent simulations, etc.) and
for various aspects of the molecular evolution (substitutions, indels, and among-site
variability in mutation rates).
The first subsection below outlines the higher-level information functions, and
the second subsection details the molecular evolution functions.


#### Higher-level method information

There are five ways to generate variants from the reference genome, and
each has a function associated with it.
The names of these functions follow the form `vars_X` for method `X`,
and information on all of the function can be found in the `vars_functions` documentation.
The outputs of these functions are meant to be passed to the `vars_info` argument
in `create_variants`.


The first two methods directly specify numbers and locations of mutations and
therefore do not require any phylogenomic methods in `jackalope`.
First, a variant call format (VCF) file can directly specify mutations for each
variant (function `vars_vcf`).
This method works using the `vcfR` package `r citep(citation("vcfR"))` and
is the only method that does not require any molecular-evolution information.
Second, matrices of segregating sites from coalescent output can provide the locations
of mutations (function `vars_ssites`).
Molecular evolution information passed to `create_variants` then informs the sampling
for the type of mutation at each site.
The segregating-site information can take the form of 
(1\) a coalescent-simulator object from the `scrm` `r citep(citation("scrm"))` or
`coala` `r citep(citation("coala"))` package, or
(2\) a file containing output from a coalescent simulator in the format of the
`ms` `r citep("10.1093/bioinformatics/18.2.337")` or 
`msms` `r citep("10.1093/bioinformatics/btq322")` programs.


The last three methods simulate sequences along phylogenies.
In the first of these methods,
phylogenetic tree(s) can be directly input from either `phylo` object(s) or
NEWICK file(s) (function `vars_phylo`).
One tree can be used for all genome sequences, or each sequence can use a separate tree.
In the second method, users can pass an estimate for $\theta$, the population-scaled
mutation rate (function `vars_theta`).
A random coalescent tree is first generated using the `rcoal` function
in the `ape` package `r citep(citation("ape"))`.
Then, its total tree length is scaled to be
$\theta / \mu \sum_{i=1}^{n-1}{1 / i}$ for $n$ variants and an equilibrium
mutation rate of $\mu$.
The last method allows for simulation of recombination by simulating along
gene trees that can differ both within and among reference sequences
(function `vars_gtrees`).
Similarly to simulations using coalescent segregating sites, gene trees can be
from `scrm` or `coala` objects, or from `ms`-style output files.

For the phylogenomic methods, variants are simulated along tree branches by
generating exponential wait times
for the Markov "jump" chain for each sequence,
where the rate of the exponential distribution is the sum of mutation rates for
all nucleotides in the sequence `r old_ref("Yang_2006")`.
At each jump, a position on the sequence is sampled with a probability proportional to
the mutation rate for that position.
A position's mutation rate is the product of its "gamma distance"
(determined by among-site variability in mutation rates) and the overall mutation rate
for the nucleotide at that position
(determined by the summed indel and substitution rates).
After sampling a position, a mutation type is sampled with probabilities
proportional to the rate of each mutation type for the nucleotide
present at the sampled position.
Jumps are performed until the summed length of all jumps is greater than the
branch length.


Because sampling of mutation positions incorporates both among-site and among-nucleotide 
variability in mutation rates,
users can separately specify rate variation that occurs due to
(1\) where the nucleotides are positioned on the sequence molecule and
(2\) the chemical structures of the nucleotides themselves.
To accomplish this, `jackalope` first splits each sequence into
smaller regions, where each region contains the same gamma distance.
The nucleotide-level rates are then summed by region and multiplied by the region's
gamma distance to get the region's overall rate.
I used these total rates as weights to sample regions, and
I incorporated a binary search tree to speed this sampling.
Simple inversion sampling is used to sample within a region.


Mutation-type sampling is performed by creating 4 vectors (one for each nucleotide),
each containing all possible mutation types:
substitutions to other nucleotides and insertions/deletions of all specified lengths.
I then use alias sampling
`r citep(list("10.1049/el:19740097", "10.1080/00031305.1979.10482697"))`
to sample within this vector.




#### Molecular evolution

Molecular evolution information is provided to the `create_variants`
function through organizing functions that are specific to the type of information:
substitutions, indels (insertions and deletions),
and variation in mutation rates among sites.
Substitutions use the `sub_models` group of functions,
indels use the `indels` function,
and among-site variation uses the `site_var` function.
A table of rates from `r old_ref("Sung_2016", FALSE)` is included in the package
as a guide for reasonable rates to use.


Each substitution model uses its own function of the pattern `sub_M` for model `M`,
and the provided `sub_models` documentation includes information to help
users choose among them.
The following substitution models can be employed:
TN93 `r old_ref('TN93')`,
JC69 `r old_ref('JC69')`,
K80 `r citep("10.1007/BF01731581")`,
F81 `r citep("10.1007/BF01734359")`,
HKY85 `r old_ref(c('Hasegawa_1985', 'Hasegawa_1984'))`, 
F84 `r old_ref("Thorne_1992")`,
GTR `r old_ref("Tavare_1986gtr")`,
and UNREST `r old_ref("Yang_1994")`.
If using the UNREST model, equilibrium nucleotide frequencies ($\mathbf{\pi}$) are 
calculated by solving for $\mathbf{\pi} \mathbf{Q} = 0$, where $\mathbf{Q}$ is the
substitution rate matrix.
This is done by finding the left eigenvector of $\mathbf{Q}$ that
corresponds to the eigenvalue closest to zero.


Providing insertion and deletion information is organized in the `indels` function.
It first requires an overall rate parameter, which is for the sum among all
nucleotides; indel rates do not differ among nucleotides.
The `indels` function also requires information about the relative rates of
indels of different sizes, which can be provided in 3 different ways.
First, rates can be proportional to $\exp(-u)$ for indel length $u$ from
1 to the maximum possible length, $M$ `r citep("10.1101/gr.112326.110")`.
Second, rates can be generated from a Lavalette distribution, 
where the rate for length $u$ is proportional to
$\left[{u M / (M - u + 1)}\right]^{-a}$ `r citep("10.1093/molbev/msp098")`.
Third, relative rates can be specified directly by providing a length-$M$
numeric vector of positive values.
Indels up to 1 Mb are allowed.


Among-site variation in mutation rates, specified in the `site_var` function,
is included either by generating gamma distances from a distribution
or by passing them manually.
Gamma distances are generated from a Gamma distribution with a fixed mean of 1
and with a shape parameter provided by the user; 
a proportion of these regions can optionally be invariant.
Users can also pass a list of matrices, one for each reference sequence,
with a gamma distance and end point for each sequence region.
The gamma distances can optionally be written to a BED file.




### The `variants` class


Haploid variant information is stored in the `variants` class.
Similarly to `ref_genome`, this R6 class wraps a pointer to a C++ object
that stores all the information, and it was designed to prevent copying of large
objects in memory.
The underlying C++ class does not store whole variant genomes, but
rather just their mutation information---this dramatically reduces memory usage.
Methods in `variants` allow the user to view the number of sequences/variants,
variant sequence sizes, sequence/variant names, and individual variant-sequence strings.
Users can also edit variant names, remove one or more variants by name,
add blank variants, duplicate existing variants,
and manually add mutations.
Variant information can be written to VCF files using the `write_vcf` function,
where each variant can optionally be considered one of multiple haplotypes for
samples with ploidy levels > 1.
Alternatively, variant genomes can be written to separate FASTA files
using `write_fasta`.



### Simulate sequencing data


Both R6 classes `ref_genome` and `variants` can be input to the sequencing functions
`illumina` and `pacbio`.
Sequences from which reads are derived are sampled with weights proportional to
their length.
If a `variants` object is provided, individual variants are sampled with equal
probabilities by default.
Alternatively, the user can specify sampling weights for each variant
to simulate the library containing differing amounts of DNA from each.
Both methods also allow for a probability of read duplication, which might occur
due to PCR in either method and from optical duplicates in Illumina sequencing.
`jackalope` can create reads using multiple threads by having a read "pool" for
each thread and having pools write to file only when they are full.
This reduces conflicts that occur when multiple threads attempt to write to disk
at the same time.
The size of a "full" pool can be adjusted, and larger sizes should increase both
speed and memory usage.
Reads are output to FASTQ files.


Function `illumina` simulates single, paired-ended, or mate-pair Illumina reads,
while `pacbio` simulates reads from the Pacific Biosciences (PacBio) platform.
Illumina read simulation is based on the ART program
`r citep("10.1093/bioinformatics/btr708")`, and
PacBio read simulation is based on SimLoRD `r citep("10.1093/bioinformatics/btw286")`.
Each was re-coded in C++ to more seemlessly integrate into `jackalope`.
Function inputs emulate the program they were based on.




## Performance

Performance was tested on a 2013 MacBook Pro running macOS Mojave (version 10.14.4)
with a 2.6GHz Intel Core i5 processor and 8 GB RAM.
Time and maximum memory used were measured by using the `time` command from the terminal.
For each test, 10 runs of each program were tested in random order.








## Example usage

```{r examples-seed, eval = TRUE, echo = FALSE}
set.seed(1840304462)
```


This section provides brief examples of how `jackalope` can be used
to generate sequencing data that can inform some common sampling decisions for HTS
studies.
These examples only show how to produce the output from `jackalope`, as
a review of different pipelines is beyond the scope of the present manuscript.

For an example reference assembly, I used the *Drosophila melanogaster* assembly
(version 6.27) downloaded from `flybase.org` `r citep("10.1093/nar/gky1003")`.
After downloading, I read the compressed FASTA file, filtered out
scaffolds by using a size threshold, and manually removed the sex chromosomes
using the following code:

```{r examples-read-assembly-for-eval, eval = TRUE, echo = FALSE}
ref <- read_fasta("examples/dmel-6.27.fasta.gz",
                  cut_names = TRUE)
ref$filter_seqs(1e6, method = "size")
ref$rm_seqs(c("X", "Y"))
```
```{r examples-read-assembly-for-show}
ref <- read_fasta("dmel-6.27.fasta.gz",
                  cut_names = TRUE)
ref$filter_seqs(1e6, method = "size")
ref$rm_seqs(c("X", "Y"))
```


This resulted in the following `ref_genome` object:

```{r examples-print-assembly, eval = TRUE, echo = FALSE}
print(ref)
```


For molecular-evolution information, I used the TN93 model,
an insertion rate of `2e-5` for lengths from 1 to 10,
and
a deletion rate of `1e-5` for lengths from 1 to 40.

```{r examples-mevo-objects, eval = TRUE}
sub <- sub_TN93(pi_tcag = c(0.1, 0.2, 0.3, 0.4),
                alpha_1 = 0.0001, alpha_2 = 0.0002,
                beta = 0.00015)
ins <- indels(rate = 2e-5, max_length = 10)
del <- indels(rate = 1e-5, max_length = 40)
```


### Assembling a genome

The example here produces FASTQ files from the known reference assembly that could
test strategies for how to assemble a similar genome using HTS data.

The first strategy is to use only PacBio sequencing.
The PacBio Sequel system produces up to 500,000 reads per
Single Molecule, Real-Time (SMRT) cell, so you could
run the following for two cells:

```{r examples-reads-for-assembly-pacbio}
pacbio(ref, out_prefix = "pacbio", n_reads = 2 * 500e3)
```

An alternative, hybrid strategy uses
1 SMRT cell of PacBio sequencing and
1 lane ($\sim 500$ million reads) of $2 \times 100$bp Illumina
sequencing on the HiSeq 2500 system (the default Illumina system in `jackalope`):

```{r examples-reads-for-assembly-hybrid}
pacbio(ref, out_prefix = "pacbio", n_reads = 500e3)
illumina(ref, out_prefix = "illumina", n_reads = 500e6, paired = TRUE,
         read_length = 100)
```


The last strategy combines 1 lane of $2 \times 100$bp Illumina HiSeq 2500 sequencing
with 1 flow cell of $2 \times 250$bp mate-pair sequencing on an Illumina MiSeq v3.
The mate-pair sequencing uses longer fragments (defaults are mean of 400 and
standard deviation of 100) to better cover highly
repetitive regions.

```{r examples-reads-for-assembly-illumina}
illumina(ref, out_prefix = "ill_pe", n_reads = 500e6, paired = TRUE,
         read_length = 100)
illumina(ref, out_prefix = "ill_mp", seq_sys = "MSv3",
         read_length = 250, n_reads = 50e6, matepair = TRUE, 
         frag_mean = 3000, frag_sd = 500)
```




### Estimating divergence between populations

Here, I will demonstrate how to generate population-genomic data of a type that might
be used to estimate the divergence between two populations.
I first use the `scrm` package `r citep(citation("scrm"))` to conduct 
coalescent simulations that will generate segregating sites for 40 haploid variants
from the reference genome.
Twenty of the variants are from one population, twenty from another.
The symmetrical migration rate is 100 individuals per generation.
To generate many mutations, I set the population-scaled mutation rate
($\theta = 4 N_0 \mu$) to `1000` for this example.

```{r examples-divergence-scrm, eval = TRUE}
ssites <- scrm(paste("40", ref$n_seqs(), "-t 1000 -I 2 20 20 100"))
```

Using the previously created objects for molecular evolution information (`sub`,
`ins`, and `del`), I create variants from the reference genome:

```{r examples-divergence-create, eval = TRUE}
vars <- create_variants(ref, vars_ssites(ssites), sub, ins, del)
```

This results in the following set of variants:

```{r examples-divergence-create-print, eval = TRUE, echo = FALSE}
print(vars)
```


For a file of true divergences from the reference genome, the `write_vcf` function
writes the `variants` object to a VCF file:

```{r examples-divergence-write-vcf}
write_vcf(vars, "variants")
```


Lastly, I simulate 1 lane of $2 \times 100$bp Illumina HiSeq 2500 sequencing.
In this case, individuals within a population are pooled, and the population
sequences are derived from are identified by barcodes.

```{r examples-divergence-illumina-pool}
illumina(vars, out_prefix = "vars_illumina", n_reads = 500e6, paired = TRUE,
         read_length = 100, barcodes = c(rep("AACCGCGG", 20), 
                                         rep("GGTTATAA", 20)))
```


The below example instead has each individual variant's reads output to separate
FASTQ files:

```{r examples-divergence-illumina-individual}
illumina(vars, out_prefix = "vars_illumina", n_reads = 500e6, paired = TRUE,
         read_length = 100, sep_files = TRUE)
```



### Constructing a phylogeny

#### From one phylogenetic tree

This section shows how `jackalope` can generate variants from a phylogeny, then
simulate sequencing data from those variants to test phylogeny reconstruction methods.
First, I generated a random coalescent tree of 10 species using the  `ape` package
`r citep(citation("ape"))`.

```{r examples-phylogeny-tree, eval = TRUE}
tree <- ape::rcoal(10)
```

Then I input that to the `create_variants` function alongside the molecular evolution
information.

```{r examples-phylogeny-tree-create-for-show}
vars <- create_variants(ref, vars_phylo(tree), sub, ins, del)
```
```{r examples-phylogeny-tree-create-for-eval, eval = TRUE, echo = FALSE}
vars <- create_variants(ref, vars_phylo(tree), sub, ins, del,
                        n_threads = 4)
```


This results in the following `variants` object:

```{r examples-phylogeny-tree-variants-print, echo = FALSE, eval = TRUE}
print(vars)
```


Now I can generate data for 1 flow cell of $2 \times 250$bp sequencing
on an Illumina MiSeq v3.

```{r examples-phylogeny-tree-illumina}
illumina(vars, out_prefix = "phylo_tree", seq_sys = "MSv3",
         read_length = 250, n_reads = 50e6)
```



#### From gene trees

Similar to the section above, the ultimate goal here is to test phylogeny
reconstruction methods.
The difference in this section is that instead of using a single, straightforward
phylogeny, I use multiple gene trees per sequence.
In the species used in these simulations, species 3 diverged from 1 and 2 at $t = 1.0$,
where $t$ indicates time into the past and is in units of $4 N_0$ generations.
Species 1 and 2 diverged at $t = 0.5$.
I assume a recombination rate of $1 / (4 N_0)$ recombination events per sequence
per generation.
Because each sequence is a different length and the length is required for including
a recombination rate, I had to run `scrm` separately for each sequence.
There are 4 diploid individuals sampled per species.


```{r examples-phylogeny-gtrees-scrm, eval = TRUE}
# Run scrm for one sequence size:
one_seq <- function(size) {
    sims <- scrm(
        paste("24 1",
              # Output gene trees:
              "-T",
              # Recombination:
              "-r 1", size,
              # 3 species with no ongoing migration:
              "-I 3", paste(rep("8", 3), collapse = " "), "0",
              # Species 2 derived from 1 at time 1.0:
              "-ej 1.0 2 1",  
              # Species 3 derived from 2 at time 0.5:
              "-ej 0.5 3 2"
        ))
    return(sims$trees[[1]])
}
# For all sequences:
gtrees <- list(trees = lapply(ref$sizes(), one_seq))
```

```{r examples-phylogeny-gtrees-create-variants, echo = FALSE, eval = TRUE, cache=TRUE}
# Takes ~1.5 min
vars <- create_variants(ref, vars_gtrees(gtrees),
                        sub, ins, del,
                        n_threads = 4)
```
```{r examples-phylogeny-gtrees-create-variants-for-show}
vars <- create_variants(ref, vars_gtrees(gtrees),
                        sub, ins, del)
```


This results in the following `variants` object:

```{r examples-phylogeny-gtrees-variants-print, echo = FALSE, eval = TRUE, cache=TRUE}
print(vars)
```


To store mutation information by diploid sample, the `write_vcf` function writes
the `variants` object to a VCF file.
It assigns haplotypes to diploid samples using a matrix for the
`sample_matrix` argument:

```{r examples-phylogeny-write-vcf}
write_vcf(vars, out_prefix = "var_gtrees",
          sample_matrix = matrix(1:vars$n_vars(), ncol = 2, byrow = TRUE))
```


Now I can generate data for 1 flow cell of $2 \times 250$bp sequencing
on an Illumina MiSeq v3.

```{r examples-phylogeny-gtrees-illumina}
illumina(ref, out_prefix = "phylo_gtrees",
         seq_sys = "MSv3",
         read_length = 250,
         n_reads = 50e6)
```







## Conclusion


`jackalope` outperforms popular stand-alone programs for phylogenomic and HTS
simulation and combines their functionalities into one cohesive package.
Although it does not provide the in-built power of full pipelines like `NGSphy`,
simulations using `jackalope` are much simpler to implement.
Moreover, the flexibility of `jackalope` allows power users to manually
provide inputs in many instances where the in-built functionality may not suffice.


This package should inform research design for projects employing HTS,
particularly those focusing on population genomics or phylogenomics.
Output from `jackalope` will help develop more specific sequencing goals 
in funding applications and estimate the power of a given sequencing design.
Furthermore, `jackalope` can be used to test bioinformatic pipelines under assumptions of
much more complex demographic histories than most current HTS simulation 
platforms allow.





<!-- ## Acknowledgements -->

<!-- This research was performed using the compute resources and assistance of the -->
<!-- UW--Madison Center For High Throughput Computing (CHTC) in the Department of -->
<!-- Computer Sciences. -->
<!-- The CHTC is supported by UW--Madison, the Advanced Computing Initiative, the -->
<!-- Wisconsin Alumni Research Foundation, the Wisconsin Institutes for Discovery, -->
<!-- and the National Science Foundation, and is an active member of the Open Science -->
<!-- Grid, which is supported by the National Science Foundation and the U.S. Department -->
<!-- of Energy's Office of Science. -->


# References

```{r biblio, message = FALSE, eval = TRUE, echo = FALSE}
write.bibtex(file="references.bib")
```
